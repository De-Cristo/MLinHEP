{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d0d65ef-c0b4-4454-b534-5e7dd19158b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d572e416-007c-4a7d-bf54-8a11b8295199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load Parquet files and extract relevant data\n",
    "def load_and_label_parquet_files(input_dir, signal_prefix=\"ZH\"):\n",
    "    \"\"\"\n",
    "    Load all Parquet files from a directory and assign labels based on file names.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_dir (str): Path to the directory containing Parquet files.\n",
    "    - signal_prefix (str): Prefix to identify signal files.\n",
    "    \n",
    "    Returns:\n",
    "    - list: Column names from the first Parquet file.\n",
    "    - pd.DataFrame: Summary DataFrame with name (prefix), event number, and signal flag.\n",
    "    \"\"\"\n",
    "    parquet_files = [os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith('.parquet')]\n",
    "    if not parquet_files:\n",
    "        raise FileNotFoundError(f\"No Parquet files found in {input_dir}\")\n",
    "    \n",
    "    data_summary = []\n",
    "    columns = None\n",
    "    \n",
    "    for file in parquet_files:\n",
    "        # Extract prefix from the file name\n",
    "        prefix = os.path.basename(file).split('_')[0]\n",
    "        \n",
    "        # Determine label: 1 for signal, 0 for background\n",
    "        signal_flag = 1 if prefix == signal_prefix else 0\n",
    "        \n",
    "        # Load Parquet file\n",
    "        print(f\"Loading {file}...\")\n",
    "        df = pd.read_parquet(file)\n",
    "        \n",
    "        # Save column names from the first file\n",
    "        if columns is None:\n",
    "            columns = list(df.columns)\n",
    "        \n",
    "        # Add to summary\n",
    "        data_summary.append({\n",
    "            \"name\": prefix,\n",
    "            \"event number\": len(df),\n",
    "            \"signal\": signal_flag\n",
    "        })\n",
    "    \n",
    "    # Create a summary DataFrame\n",
    "    summary_df = pd.DataFrame(data_summary)\n",
    "\n",
    "    # Combine rows with the same prefix and sum event numbers\n",
    "    summary_df = summary_df.groupby([\"name\", \"signal\"], as_index=False).sum()\n",
    "    \n",
    "    return columns, summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae23af85-5ee0-4cda-9a40-2952ca60ef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to training data\n",
    "input_dir = \"./data/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fa151ad-e08e-4988-bfce-2ead6b557e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ./data/train/DYto2L-2Jets_MLL-50_FxFx_2022_postEE_DiJet_bx_CR_BB_combined.parquet...\n",
      "Loading ./data/train/DYto2L-2Jets_MLL-50_FxFx_2022_postEE_DiJet_bx_CR_B_combined.parquet...\n",
      "Loading ./data/train/DYto2L-2Jets_MLL-50_FxFx_2022_postEE_DiJet_bx_CR_LF_combined.parquet...\n",
      "Loading ./data/train/DYto2L-2Jets_MLL-50_FxFx_2022_postEE_DiJet_bx_CR_TT_combined.parquet...\n",
      "Loading ./data/train/DYto2L-2Jets_MLL-50_FxFx_2022_postEE_DiJet_bx_SR_2L2B_combined.parquet...\n",
      "Loading ./data/train/DYto2L-2Jets_MLL-50_FxFx_2022_postEE_DiJet_cx_CR_BB_combined.parquet...\n",
      "Loading ./data/train/DYto2L-2Jets_MLL-50_FxFx_2022_postEE_DiJet_cx_CR_B_combined.parquet...\n",
      "Loading ./data/train/DYto2L-2Jets_MLL-50_FxFx_2022_postEE_DiJet_cx_CR_LF_combined.parquet...\n",
      "Loading ./data/train/DYto2L-2Jets_MLL-50_FxFx_2022_postEE_DiJet_cx_CR_TT_combined.parquet...\n",
      "Loading ./data/train/DYto2L-2Jets_MLL-50_FxFx_2022_postEE_DiJet_cx_SR_2L2B_combined.parquet...\n",
      "Loading ./data/train/DYto2L-2Jets_MLL-50_FxFx_2022_postEE_DiJet_incl_CR_BB_combined.parquet...\n",
      "Loading ./data/train/DYto2L-2Jets_MLL-50_FxFx_2022_postEE_DiJet_incl_CR_B_combined.parquet...\n",
      "Loading ./data/train/DYto2L-2Jets_MLL-50_FxFx_2022_postEE_DiJet_incl_CR_LF_combined.parquet...\n",
      "Loading ./data/train/DYto2L-2Jets_MLL-50_FxFx_2022_postEE_DiJet_incl_CR_TT_combined.parquet...\n",
      "Loading ./data/train/DYto2L-2Jets_MLL-50_FxFx_2022_postEE_DiJet_incl_SR_2L2B_combined.parquet...\n",
      "Loading ./data/train/DYto2L-2Jets_MLL-50_FxFx_2022_postEE_DiJet_ll_CR_BB_combined.parquet...\n",
      "Loading ./data/train/DYto2L-2Jets_MLL-50_FxFx_2022_postEE_DiJet_ll_CR_B_combined.parquet...\n",
      "Loading ./data/train/DYto2L-2Jets_MLL-50_FxFx_2022_postEE_DiJet_ll_CR_LF_combined.parquet...\n",
      "Loading ./data/train/DYto2L-2Jets_MLL-50_FxFx_2022_postEE_DiJet_ll_CR_TT_combined.parquet...\n",
      "Loading ./data/train/DYto2L-2Jets_MLL-50_FxFx_2022_postEE_DiJet_ll_SR_2L2B_combined.parquet...\n",
      "Loading ./data/train/DYto2L-2Jets_MLL-50_FxFx_2022_preEE_DiJet_bx_CR_BB_combined.parquet...\n",
      "Loading ./data/train/DYto2L-2Jets_MLL-50_FxFx_2022_preEE_DiJet_bx_CR_B_combined.parquet...\n",
      "Loading ./data/train/DYto2L-2Jets_MLL-50_FxFx_2022_preEE_DiJet_bx_CR_LF_combined.parquet...\n",
      "Loading ./data/train/DYto2L-2Jets_MLL-50_FxFx_2022_preEE_DiJet_bx_CR_TT_combined.parquet...\n",
      "Loading ./data/train/DYto2L-2Jets_MLL-50_FxFx_2022_preEE_DiJet_bx_SR_2L2B_combined.parquet...\n",
      "Loading ./data/train/DYto2L-2Jets_MLL-50_FxFx_2022_preEE_DiJet_cx_CR_BB_combined.parquet...\n",
      "Loading ./data/train/DYto2L-2Jets_MLL-50_FxFx_2022_preEE_DiJet_cx_CR_B_combined.parquet...\n",
      "Loading ./data/train/DYto2L-2Jets_MLL-50_FxFx_2022_preEE_DiJet_cx_CR_LF_combined.parquet...\n",
      "Loading ./data/train/DYto2L-2Jets_MLL-50_FxFx_2022_preEE_DiJet_cx_CR_TT_combined.parquet...\n",
      "Loading ./data/train/DYto2L-2Jets_MLL-50_FxFx_2022_preEE_DiJet_cx_SR_2L2B_combined.parquet...\n",
      "Loading ./data/train/DYto2L-2Jets_MLL-50_FxFx_2022_preEE_DiJet_incl_CR_BB_combined.parquet...\n",
      "Loading ./data/train/DYto2L-2Jets_MLL-50_FxFx_2022_preEE_DiJet_incl_CR_B_combined.parquet...\n",
      "Loading ./data/train/DYto2L-2Jets_MLL-50_FxFx_2022_preEE_DiJet_incl_CR_LF_combined.parquet...\n",
      "Loading ./data/train/DYto2L-2Jets_MLL-50_FxFx_2022_preEE_DiJet_incl_CR_TT_combined.parquet...\n",
      "Loading ./data/train/DYto2L-2Jets_MLL-50_FxFx_2022_preEE_DiJet_incl_SR_2L2B_combined.parquet...\n",
      "Loading ./data/train/DYto2L-2Jets_MLL-50_FxFx_2022_preEE_DiJet_ll_CR_BB_combined.parquet...\n",
      "Loading ./data/train/DYto2L-2Jets_MLL-50_FxFx_2022_preEE_DiJet_ll_CR_B_combined.parquet...\n",
      "Loading ./data/train/DYto2L-2Jets_MLL-50_FxFx_2022_preEE_DiJet_ll_CR_LF_combined.parquet...\n",
      "Loading ./data/train/DYto2L-2Jets_MLL-50_FxFx_2022_preEE_DiJet_ll_CR_TT_combined.parquet...\n",
      "Loading ./data/train/DYto2L-2Jets_MLL-50_FxFx_2022_preEE_DiJet_ll_SR_2L2B_combined.parquet...\n",
      "Loading ./data/train/TTTo2L2Nu_2022_postEE_CR_BB_combined.parquet...\n",
      "Loading ./data/train/TTTo2L2Nu_2022_postEE_CR_B_combined.parquet...\n",
      "Loading ./data/train/TTTo2L2Nu_2022_postEE_CR_LF_combined.parquet...\n",
      "Loading ./data/train/TTTo2L2Nu_2022_postEE_CR_TT_combined.parquet...\n",
      "Loading ./data/train/TTTo2L2Nu_2022_postEE_SR_2L2B_combined.parquet...\n",
      "Loading ./data/train/TTTo2L2Nu_2022_preEE_CR_BB_combined.parquet...\n",
      "Loading ./data/train/TTTo2L2Nu_2022_preEE_CR_B_combined.parquet...\n",
      "Loading ./data/train/TTTo2L2Nu_2022_preEE_CR_LF_combined.parquet...\n",
      "Loading ./data/train/TTTo2L2Nu_2022_preEE_CR_TT_combined.parquet...\n",
      "Loading ./data/train/TTTo2L2Nu_2022_preEE_SR_2L2B_combined.parquet...\n",
      "Loading ./data/train/ZH_Hto2B_Zto2L_2022_postEE_CR_BB_combined.parquet...\n",
      "Loading ./data/train/ZH_Hto2B_Zto2L_2022_postEE_CR_B_combined.parquet...\n",
      "Loading ./data/train/ZH_Hto2B_Zto2L_2022_postEE_CR_LF_combined.parquet...\n",
      "Loading ./data/train/ZH_Hto2B_Zto2L_2022_postEE_CR_TT_combined.parquet...\n",
      "Loading ./data/train/ZH_Hto2B_Zto2L_2022_postEE_SR_2L2B_combined.parquet...\n",
      "Loading ./data/train/ZH_Hto2B_Zto2L_2022_preEE_CR_BB_combined.parquet...\n",
      "Loading ./data/train/ZH_Hto2B_Zto2L_2022_preEE_CR_B_combined.parquet...\n",
      "Loading ./data/train/ZH_Hto2B_Zto2L_2022_preEE_CR_LF_combined.parquet...\n",
      "Loading ./data/train/ZH_Hto2B_Zto2L_2022_preEE_CR_TT_combined.parquet...\n",
      "Loading ./data/train/ZH_Hto2B_Zto2L_2022_preEE_SR_2L2B_combined.parquet...\n",
      "Columns in the training files:\n",
      "['weight', 'events_nJet', 'events_dilep_m', 'events_dilep_pt', 'events_dilep_dr', 'events_dilep_deltaPhi', 'events_dilep_deltaEta', 'events_dibjet_m', 'events_dibjet_pt', 'events_dibjet_dr', 'events_dibjet_deltaPhi', 'events_dibjet_deltaEta', 'events_dibjet_pt_max', 'events_dibjet_pt_min', 'events_dibjet_mass_max', 'events_dibjet_mass_min', 'events_dibjet_BvsL_max', 'events_dibjet_BvsL_min', 'events_dibjet_CvsL_max', 'events_dibjet_CvsL_min', 'events_dibjet_CvsB_max', 'events_dibjet_CvsB_min', 'events_VHbb_pt_ratio', 'events_VHbb_deltaPhi', 'events_VHbb_deltaR']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>signal</th>\n",
       "      <th>event number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DYto2L-2Jets</td>\n",
       "      <td>0</td>\n",
       "      <td>712705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TTTo2L2Nu</td>\n",
       "      <td>0</td>\n",
       "      <td>67843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZH</td>\n",
       "      <td>1</td>\n",
       "      <td>412946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name  signal  event number\n",
       "0  DYto2L-2Jets       0        712705\n",
       "1     TTTo2L2Nu       0         67843\n",
       "2            ZH       1        412946"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load files and analyze\n",
    "try:\n",
    "    columns, analysis_df = load_and_label_parquet_files(input_dir)\n",
    "    \n",
    "    # Display column names\n",
    "    print(\"Columns in the training files:\")\n",
    "    print(columns)\n",
    "    \n",
    "    # Display analysis summary in the notebook\n",
    "    display(analysis_df)\n",
    "except FileNotFoundError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e41a775-5e08-4ad9-8236-ef4c01777b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRL-style LaTeX table saved to file_summary_prl.tex\n",
      "\\begin{table}[h!]\n",
      "\\centering\n",
      "\\begin{tabular}{lrl}\n",
      "\\hline\n",
      "Name & Event Number & Signal \\\\\n",
      "\\hline\n",
      "DYto2L-2Jets & 712705 & 0 \\\\\n",
      "TTTo2L2Nu & 67843 & 0 \\\\\n",
      "ZH & 412946 & 1 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\caption{Summary of Training Files.}\n",
      "\\label{tab:training_summary}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate a PRL-style LaTeX table\n",
    "def generate_prl_style_table(df, output_file=None):\n",
    "    \"\"\"\n",
    "    Generate a PRL-style LaTeX table summarizing the file analysis.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): DataFrame containing the analysis summary.\n",
    "    - output_file (str): Path to save the LaTeX table (optional).\n",
    "    \n",
    "    Returns:\n",
    "    - str: PRL-style LaTeX table as a string.\n",
    "    \"\"\"\n",
    "    # Define the LaTeX structure for PRL format\n",
    "    latex_table = (\n",
    "        \"\\\\begin{table}[h!]\\n\"\n",
    "        \"\\\\centering\\n\"\n",
    "        \"\\\\begin{tabular}{lrl}\\n\"  # Define columns: l = left-aligned, r = right-aligned\n",
    "        \"\\\\hline\\n\"\n",
    "        \"Name & Event Number & Signal \\\\\\\\\\n\"\n",
    "        \"\\\\hline\\n\"\n",
    "    )\n",
    "\n",
    "    # Add rows\n",
    "    for _, row in df.iterrows():\n",
    "        latex_table += f\"{row['name']} & {row['event number']} & {row['signal']} \\\\\\\\\\n\"\n",
    "\n",
    "    # Close the table\n",
    "    latex_table += (\n",
    "        \"\\\\hline\\n\"\n",
    "        \"\\\\end{tabular}\\n\"\n",
    "        \"\\\\caption{Summary of Training Files.}\\n\"\n",
    "        \"\\\\label{tab:training_summary}\\n\"\n",
    "        \"\\\\end{table}\\n\"\n",
    "    )\n",
    "\n",
    "    # Save the table if requested\n",
    "    if output_file:\n",
    "        with open(output_file, \"w\") as f:\n",
    "            f.write(latex_table)\n",
    "        print(f\"PRL-style LaTeX table saved to {output_file}\")\n",
    "    \n",
    "    return latex_table\n",
    "\n",
    "# Generate and display the PRL-style LaTeX table\n",
    "prl_latex_table = generate_prl_style_table(analysis_df, output_file=\"file_summary_prl.tex\")\n",
    "print(prl_latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a6c38f-640f-4753-9961-6d72d68623d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_umd_env)",
   "language": "python",
   "name": "my_emd_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
